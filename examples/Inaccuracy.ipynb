{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Inaccuracy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastautoml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b5b726c61c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInaccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastautoml'"
     ]
    }
   ],
   "source": [
    "from fastautoml.fastautoml import Inaccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare score with inaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X    = data.data\n",
    "y    = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc = Inaccuracy()\n",
    "inacc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a collection of decision tree classifers with different levels of depth, compute a classical score and the new inaccuracy metric, and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores       = list()\n",
    "inaccuracies = list()\n",
    "\n",
    "for i in range(1, 20):\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=42)\n",
    "    tree.fit(X, y)\n",
    "    \n",
    "    scores.append(1 - tree.score(X, y))\n",
    "    inaccuracies.append(inacc.inaccuracy_model(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,20), scores, label=\"Score\")\n",
    "plt.plot(range(1,20), inaccuracies, label=\"Inaccuracy\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Tree Depth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the behaviour of score and inaccuracy when we introduce more errors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_leaf=5, random_state=42)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X, y)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we make one hundred times the same error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2     = X.copy()\n",
    "y2     = y.copy()\n",
    "for i in np.arange(100):\n",
    "    X2 = np.append(X2, [X[0]], axis=0)\n",
    "    y2 = np.append(y2, (y[0]+1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X2, y2)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of nescience states that making one hundred times the same error is not that bad. Let's see what happens if we make one hundred different errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3     = X.copy()\n",
    "y3     = y.copy()\n",
    "for i in np.arange(100):\n",
    "    index  = np.random.randint(X.shape[0])\n",
    "    X3     = np.append(X3, [X[index]], axis=0)\n",
    "    y3     = np.append(y3, (y[index]+1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X3, y3)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X3, y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making one hundred different errors is worse than making one hundred times the same error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the behaviour of score and inaccuracy in a hihgly imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list()\n",
    "score = list()\n",
    "inacc = list()\n",
    "\n",
    "inaccuracy = Inaccuracy()\n",
    "\n",
    "for i in np.arange(1, 100):\n",
    "                    \n",
    "    X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "                               class_sep=2, flip_y=0, weights=[0.95,0.05])\n",
    "\n",
    "    inaccuracy.fit(X, y)\n",
    "        \n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=i)\n",
    "    tree.fit(X, y)\n",
    "\n",
    "    depth.append(i)        \n",
    "    score.append(1 - tree.score(X, y))\n",
    "    inacc.append(inaccuracy.inaccuracy_model(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(depth, score, label=\"Score\")\n",
    "plt.plot(depth, inacc, label=\"Inaccuracy\")\n",
    "plt.title(\"Isotropic Gaussian Blobs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Minimum Leaf Size\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the score metric is not able to work with imbalanced datasts, a problem that is not suffered by the new inaccuracy metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
